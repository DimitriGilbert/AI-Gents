#!/bin/bash
# @parseArger-begin
# @parseArger-help "Race several models, then judge and combine the outputs" --option "help" --short-option "h"
# @parseArger-verbose --option "verbose" --level "0" --quiet-option "quiet"
_has_colors=0
if [ -t 1 ]; then # Check if stdout is a terminal
	ncolors=$(tput colors 2>/dev/null)
	if [ -n "$ncolors" ] && [ "$ncolors" -ge 8 ]; then
		_has_colors=1
	fi
fi
# @parseArger-declarations
# @parseArger pos prompt "your prompt"
# @parseArger opt model "provider:model-id format" --short m --repeat
# @parseArger opt judge-model "provider:model-id, model used to judge the result, forces --judge" --short j --repeat
# @parseArger opt combine "provider:model-id, model used to combine responses"
# @parseArger opt log-file "save everything to log"
# @parseArger flag judge "judge race result"
# @parseArger flag judge-individual "judge each response on its own"
# @parseArger flag judge-together "judge all response together" --on
# @parseArger flag parallel "execute task in parallel when  possible" --on --no-name sequential
# @parseArger-declarations-end

# @parseArger-utils
_helpHasBeenPrinted=1;
_SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd -P)";
# @parseArger-utils-end

# @parseArger-parsing

__cli_arg_count=$#;

die()
{
	local _ret=1
    if [[ -n "$2" ]] && [[ "$2" =~ ^[0-9]+$ ]]; then
   	_ret="$2"
    fi
	test "${_PRINT_HELP:-no}" = yes && print_help >&2
	log "$1" -3 >&2
	exit "${_ret}"
}


begins_with_short_option()
{
	local first_option all_short_options=''
	first_option="${1:0:1}"
	test "$all_short_options" = "${all_short_options/$first_option/}" && return 1 || return 0
}

# POSITIONALS ARGUMENTS
_positionals=();
_optional_positionals=();
_arg_prompt="";
# OPTIONALS ARGUMENTS
_arg_model=()
_arg_judge_model=()
_arg_combine=
_arg_log_file=
# FLAGS
_arg_judge="off"
_arg_judge_individual="off"
_arg_judge_together="on"
_arg_parallel="on"
# NESTED
_verbose_level="0";



print_help()
{
	_triggerSCHelp=1;

	if [[ "$_helpHasBeenPrinted" == "1" ]]; then
		_helpHasBeenPrinted=0;
		echo -e "Race several models, then judge and combine the outputs:"
	echo -e "	prompt: your prompt"
	echo -e "	-m, --model <model>: provider:model-id format, repeatable"
	echo -e "	-j, --judge-model <judge-model>: provider:model-id, model used to judge the result, forces --judge, repeatable"
	echo -e "	--combine <combine>: provider:model-id, model used to combine responses"
	echo -e "	--log-file <log-file>: save everything to log"
	echo -e "	--judge|--no-judge: judge race result"
	echo -e "	--judge-individual|--no-judge-individual: judge each response on its own"
	echo -e "	--judge-together|--no-judge-together: judge all response together, on by default (use --no-judge-together to turn it off)"
	echo -e "	--parallel|--sequential: execute task in parallel when  possible, on by default (use --sequential to turn it off)"
	echo -e "Usage :
	$0 <prompt> [--model <value>] [--judge-model <value>] [--combine <value>] [--log-file <value>] [--[no-]judge] [--[no-]judge-individual] [--[no-]judge-together] [--[no-]parallel]";
	fi

}

log() {
	local _arg_msg="${1}";
	local _arg_level="${2:-0}";
	if [ "${_arg_level}" -le "${_verbose_level}" ]; then
		case "$_arg_level" in
			-3)
				_arg_COLOR="\033[0;31m";
				;;
			-2)
				_arg_COLOR="\033[0;33m";
				;;
			-1)
				_arg_COLOR="\033[1;33m";
				;;
			1)
				_arg_COLOR="\033[0;32m";
				;;
			2)
				_arg_COLOR="\033[1;36m";
				;;
			3)
				_arg_COLOR="\033[0;36m";
				;;
			*)
				_arg_COLOR="\033[0m";
				;;
		esac
		if [ "${_has_colors}" == "1" ]; then
			echo -e "${_arg_COLOR}${_arg_msg}\033[0m";
		else
			echo "${_arg_msg}";
		fi
	fi
}

parse_commandline()
{
	_positionals_count=0
	while test $# -gt 0
	do
		_key="$1"
		case "$_key" in
			-m|--model)
				test $# -lt 2 && die "Missing value for the option: '$_key'" 1
				_arg_model+=("$2")
				shift
				;;
			--model=*)
				_arg_model+=("${_key##--model=}")
				;;
			-m*)
				_arg_model+=("${_key##-m}")
				;;
			
			-j|--judge-model)
				test $# -lt 2 && die "Missing value for the option: '$_key'" 1
				_arg_judge_model+=("$2")
				shift
				;;
			--judge-model=*)
				_arg_judge_model+=("${_key##--judge-model=}")
				;;
			-j*)
				_arg_judge_model+=("${_key##-j}")
				;;
			
			--combine)
				test $# -lt 2 && die "Missing value for the option: '$_key'" 1
				_arg_combine="$2"
				shift
				;;
			--combine=*)
				_arg_combine="${_key##--combine=}"
				;;
			
			--log-file)
				test $# -lt 2 && die "Missing value for the option: '$_key'" 1
				_arg_log_file="$2"
				shift
				;;
			--log-file=*)
				_arg_log_file="${_key##--log-file=}"
				;;
			
			--judge)
				_arg_judge="on"
				;;
			--no-judge)
				_arg_judge="off"
				;;
			--judge-individual)
				_arg_judge_individual="on"
				;;
			--no-judge-individual)
				_arg_judge_individual="off"
				;;
			--judge-together)
				_arg_judge_together="on"
				;;
			--no-judge-together)
				_arg_judge_together="off"
				;;
			--parallel)
				_arg_parallel="on"
				;;
			--sequential)
				_arg_parallel="off"
				;;
			-h|--help)
				print_help;
				exit 0;
				;;
			-h*)
				print_help;
				exit 0;
				;;
			--verbose)
					if [ $# -lt 2 ];then
						_verbose_level="$((_verbose_level + 1))";
					else
						_verbose_level="$2";
						shift;
					fi
					;;
				--quiet)
					if [ $# -lt 2 ];then
						_verbose_level="$((_verbose_level - 1))";
					else
						_verbose_level="-$2";
						shift;
					fi
					;;
				
				*)
				_last_positional="$1"
				_positionals+=("$_last_positional")
				_positionals_count=$((_positionals_count + 1))
				;;
		esac
		shift
	done
}


handle_passed_args_count()
{
	local _required_args_string="prompt"
	if [ "${_positionals_count}" -gt 1 ] && [ "$_helpHasBeenPrinted" == "1" ];then
		_PRINT_HELP=yes die "FATAL ERROR: There were spurious positional arguments --- we expect at most 1 (namely: $_required_args_string), but got ${_positionals_count} (the last one was: '${_last_positional}').\n\t${_positionals[*]}" 1
	fi
	if [ "${_positionals_count}" -lt 1 ] && [ "$_helpHasBeenPrinted" == "1" ];then
		_PRINT_HELP=yes die "FATAL ERROR: Not enough positional arguments - we require at least 1 (namely: $_required_args_string), but got only ${_positionals_count}.
	${_positionals[*]}" 1;
	fi
}


assign_positional_args()
{
	local _positional_name _shift_for=$1;
	_positional_names="_arg_prompt ";
	shift "$_shift_for"
	for _positional_name in ${_positional_names};do
		test $# -gt 0 || break;
		eval "if [ \"\$_one_of${_positional_name}\" != \"\" ];then [[ \"\${_one_of${_positional_name}[*]}\" =~ \"\${1}\" ]];fi" || die "${_positional_name} must be one of: $(eval "echo \"\${_one_of${_positional_name}[*]}\"")" 1;
		eval "$_positional_name=\${1}" || die "Error during argument parsing, possibly an ParseArger bug." 1;
		shift;
	done
}

print_debug()
{
	print_help
	# shellcheck disable=SC2145
	echo "DEBUG: $0 $@";
	
	echo -e "	prompt: ${_arg_prompt}";
	echo -e "	model: ${_arg_model[*]}";
	echo -e "	judge-model: ${_arg_judge_model[*]}";
	echo -e "	combine: ${_arg_combine}";
	echo -e "	log-file: ${_arg_log_file}";
	echo -e "	judge: ${_arg_judge}";
	echo -e "	judge-individual: ${_arg_judge_individual}";
	echo -e "	judge-together: ${_arg_judge_together}";
	echo -e "	parallel: ${_arg_parallel}";

}


on_interrupt() {
	die Process aborted! 130;
}


parse_commandline "$@";
handle_passed_args_count;
assign_positional_args 1 "${_positionals[@]}";
trap on_interrupt INT;



# @parseArger-parsing-end
# print_debug "$@"
# @parseArger-end

source "$_SCRIPT_DIR/common"

# Initialize log file if specified
log_to_file() {
    local message="$1"
    if [ -n "$_arg_log_file" ]; then
        echo "$message" >> "$_arg_log_file"
    fi
}

# Create markdown header in log file
if [ -n "$_arg_log_file" ]; then
    {
        echo "# Race Results"
        echo "## Prompt"
        echo "\`\`\`"
        echo "$_arg_prompt"
        echo "\`\`\`"
        echo "## Models"
        printf "* %s\n" "${_arg_model[@]}"
        echo "## Results"
    } > "$_arg_log_file"
fi

# Create temp dir for responses
tmp_dir="$(TMPDIR="${TMPDIR:-/tmp}" mktemp -d)"
trap 'rm -rf "$tmp_dir"' EXIT

# Function to run a single model
run_model() {
    local model="$1"
    local output_file="$2"
    local provider=""
    local start_time
    local first_token_time=""
    local end_time

    # Extract provider if in format provider:model
    if [[ "$model" == *":"* ]]; then
        provider="${model%%:*}"
        model="${model#*:}"
    fi

    # Run ask command and save output
    echo "Running $model..."
    start_time=$(date +%s.%N)
    
    # Run with stream to capture first token time
    "$_SCRIPT_DIR/ask" "$_arg_prompt" --model "$model" --provider "$provider" --stream 2>/dev/null | {
        while IFS= read -r line; do
            if [ -z "$first_token_time" ]; then
                first_token_time=$(date +%s.%N)
                echo "$line" > "$output_file"
            else
                echo "$line" >> "$output_file"
            fi
        done
        
        end_time=$(date +%s.%N)
        ttft=$(echo "$first_token_time - $start_time" | bc)
        total_time=$(echo "$end_time - $start_time" | bc)
        
        # Log timing information
        if [ -n "$_arg_log_file" ]; then
            {
                echo "### $model"
                echo "* Time to first token: ${ttft}s"
                echo "* Total response time: ${total_time}s"
                echo "#### Response"
                echo "\`\`\`"
                cat "$output_file"
                echo "\`\`\`"
            } >> "$_arg_log_file"
        fi
    }
    
    return $?
}

# Run models
declare -A responses

if [ "$_arg_parallel" == "on" ]; then
    declare -A pids
    # Run models in parallel and store their PIDs
    for model in "${_arg_model[@]}"; do
        output_file="$tmp_dir/${model//\//_}"
        run_model "$model" "$output_file" &
        pids["$model"]=$!
    done

    # Wait for all processes and collect their outputs
    for model in "${_arg_model[@]}"; do
        output_file="$tmp_dir/${model//\//_}"
        if wait "${pids[$model]}"; then
            responses["$model"]="$output_file"
        else
            log "Error: Model $model failed" -2
            log_to_file "### $model\nError: Model failed"
            rm -f "$output_file"
        fi
    done
else
    # Run models sequentially and collect outputs immediately
    for model in "${_arg_model[@]}"; do
        output_file="$tmp_dir/${model//\//_}"
        if run_model "$model" "$output_file"; then
            responses["$model"]="$output_file"
        else
            log "Error: Model $model failed" -2
            log_to_file "### $model\nError: Model failed"
            rm -f "$output_file"
        fi
    done
fi

# Only proceed if we have responses
if [ ${#responses[@]} -eq 0 ]; then
    die "No successful responses from any model" 1
fi

# Judge responses if requested
if [ "$_arg_judge" == "on" ] || [ "${#_arg_judge_model[@]}" -gt 0 ]; then
    judge_system="You are a judge evaluating AI model responses to a prompt. Rate each response and explain your reasoning."
    
    if [ -n "$_arg_log_file" ]; then
        echo -e "\n## Judgments" >> "$_arg_log_file"
    fi

    if [ "$_arg_judge_individual" == "on" ]; then
        # Judge each response individually
        if [ -n "$_arg_log_file" ]; then
            echo -e "\n### Individual Judgments" >> "$_arg_log_file"
        fi
        
        for model in "${!responses[@]}"; do
            response_file="${responses[$model]}"
            response=$(<"$response_file")
            judge_prompt="Prompt: $_arg_prompt\n\nResponse from $model:\n$response\n\nPlease evaluate this response."

            for judge_model in "${_arg_judge_model[@]}"; do
                provider=""
                if [[ "$judge_model" == *":"* ]]; then
                    provider="${judge_model%%:*}"
                    judge_model="${judge_model#*:}"
                fi

                echo -e "\nJudgment for $model by $judge_model:"
                
                start_time=$(date +%s.%N)
                judgment=$("$_SCRIPT_DIR/ask" "$judge_prompt" --model "$judge_model" --provider "$provider" --system "$judge_system")
                end_time=$(date +%s.%N)
                total_time=$(echo "$end_time - $start_time" | bc)
                
                echo "$judgment"
                
                if [ -n "$_arg_log_file" ]; then
                    {
                        echo -e "\n#### $model (by $judge_model)"
                        echo "* Judgment time: ${total_time}s"
                        echo "\`\`\`"
                        echo "$judgment"
                        echo "\`\`\`"
                    } >> "$_arg_log_file"
                fi
            done
        done
    fi

    if [ "$_arg_judge_together" == "on" ]; then
        # Judge all responses together
        if [ -n "$_arg_log_file" ]; then
            echo -e "\n### Comparative Judgment" >> "$_arg_log_file"
        fi
        
        judge_prompt="Prompt: $_arg_prompt\n\nResponses:\n"
        for model in "${!responses[@]}"; do
            response_file="${responses[$model]}"
            response=$(<"$response_file")
            judge_prompt+="\n$model:\n$response\n"
        done
        judge_prompt+="\nPlease compare and evaluate these responses."

        for judge_model in "${_arg_judge_model[@]}"; do
            provider=""
            if [[ "$judge_model" == *":"* ]]; then
                provider="${judge_model%%:*}"
                judge_model="${judge_model#*:}"
            fi

            echo -e "\nComparative judgment by $judge_model:"
            
            start_time=$(date +%s.%N)
            judgment=$("$_SCRIPT_DIR/ask" "$judge_prompt" --model "$judge_model" --provider "$provider" --system "$judge_system")
            end_time=$(date +%s.%N)
            total_time=$(echo "$end_time - $start_time" | bc)
            
            echo "$judgment"
            
            if [ -n "$_arg_log_file" ]; then
                {
                    echo -e "\n#### By $judge_model"
                    echo "* Judgment time: ${total_time}s"
                    echo "\`\`\`"
                    echo "$judgment"
                    echo "\`\`\`"
                } >> "$_arg_log_file"
            fi
        done
    fi
fi

# Combine responses if requested
if [ -n "$_arg_combine" ]; then
    if [ -n "$_arg_log_file" ]; then
        echo -e "\n## Combined Response" >> "$_arg_log_file"
    fi
    
    combine_system="You are tasked with combining multiple AI responses into a single coherent response that takes the best elements from each."
    combine_prompt="Original prompt: $_arg_prompt\n\nResponses to combine:\n"

    for model in "${!responses[@]}"; do
        response_file="${responses[$model]}"
        response=$(<"$response_file")
        combine_prompt+="\n$model:\n$response\n"
    done
    combine_prompt+="\nPlease combine these responses into a single coherent response."

    provider=""
    combine_model="$_arg_combine"
    if [[ "$combine_model" == *":"* ]]; then
        provider="${combine_model%%:*}"
        combine_model="${combine_model#*:}"
    fi

    echo -e "\nCombined response by $combine_model:"
    
    start_time=$(date +%s.%N)
    combined=$("$_SCRIPT_DIR/ask" "$combine_prompt" --model "$combine_model" --provider "$provider" --system "$combine_system")
    end_time=$(date +%s.%N)
    total_time=$(echo "$end_time - $start_time" | bc)
    
    echo "$combined"
    
    if [ -n "$_arg_log_file" ]; then
        {
            echo "* Combination time: ${total_time}s"
            echo "\`\`\`"
            echo "$combined"
            echo "\`\`\`"
        } >> "$_arg_log_file"
    fi
else
    # If not combining, just output all responses
    for model in "${!responses[@]}"; do
        response_file="${responses[$model]}"
        echo -e "\nResponse from $model:"
        cat "$response_file"
    done
fi
